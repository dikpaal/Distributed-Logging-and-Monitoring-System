events {
    worker_connections 1024;
}

http {
    # Logging format
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'upstream: $upstream_addr response_time: $upstream_response_time';

    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log warn;

    # Rate limiting zone (100 requests per second per IP)
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/s;

    # Upstream: Ingestion service instances
    # Note: These point to host machine ports when running services locally
    # Update to container names when running services in Docker
    upstream ingestion_backend {
        least_conn;  # Load balance by least connections
        server host.docker.internal:8080 max_fails=3 fail_timeout=30s;
        server host.docker.internal:8081 max_fails=3 fail_timeout=30s;
    }

    server {
        listen 80;
        server_name localhost;

        # Health check endpoint
        location /health {
            return 200 '{"status": "UP", "service": "nginx"}';
            add_header Content-Type application/json;
        }

        # Ingestion API - load balanced with rate limiting
        location /api/v1/logs {
            limit_req zone=api_limit burst=50 nodelay;
            limit_req_status 429;

            proxy_pass http://ingestion_backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Timeouts
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;

            # Error handling
            proxy_next_upstream error timeout http_502 http_503 http_504;
        }

        # Monitoring API - direct pass (no rate limiting for queries)
        location /api/v1/metrics {
            proxy_pass http://host.docker.internal:8083;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }

        # Error pages
        error_page 429 /429.json;
        location = /429.json {
            return 429 '{"error": "Too Many Requests", "message": "Rate limit exceeded"}';
            add_header Content-Type application/json;
        }

        error_page 502 503 504 /50x.json;
        location = /50x.json {
            return 502 '{"error": "Service Unavailable", "message": "Backend service is not available"}';
            add_header Content-Type application/json;
        }
    }
}
